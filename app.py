import streamlit as st
import numpy as np
import time

# ============================================================================
# æ–‡æœ¬åˆ†æå‡½æ•¸ï¼ˆåœ¨é é¢é…ç½®ä¹‹å‰å®šç¾©ï¼‰
# ============================================================================

def count_repeated_phrases(text):
    """è¨ˆç®—é‡è¤‡çš„ä¸‰è©çŸ­èª"""
    words = text.lower().split()
    if len(words) < 3:
        return 0
    
    phrases = {}
    for i in range(len(words) - 2):
        phrase = ' '.join(words[i:i+3])
        phrases[phrase] = phrases.get(phrase, 0) + 1
    
    return sum(1 for count in phrases.values() if count > 2)


def detect_formal_language(text):
    """æª¢æ¸¬æ­£å¼æªè¾­"""
    formal_words = [
        'furthermore', 'moreover', 'consequently', 'therefore',
        'nevertheless', 'however', 'regarding', 'facilitate',
        'implement', 'subsequent', 'adjacent', 'å› æ­¤', 'ç„¶è€Œ', 'å„˜ç®¡'
    ]
    
    text_lower = text.lower()
    count = sum(1 for word in formal_words if word in text_lower)
    return min(1.0, count / 3)


def check_grammar_perfection(text):
    """æª¢æŸ¥èªæ³•å®Œç¾åº¦"""
    errors = 0
    
    if '  ' in text:
        errors += text.count('  ')
    
    sentences = text.split('ã€‚')
    cap_errors = sum(1 for s in sentences if s.strip() and not s.strip()[0].isupper())
    errors += cap_errors
    
    return max(0, 1 - (errors / max(1, len(text.split()) / 10)))


def check_formulaic_patterns(text):
    """æª¢æŸ¥æ¨¡å¼åŒ–è¡¨è¿°"""
    patterns = [
        'in today\'s world',
        'it is important to',
        'in conclusion',
        'furthermore',
        'åœ¨ç•¶ä»Šä¸–ç•Œ',
        'é‡è¦çš„æ˜¯',
        'ç¸½ä¹‹',
        'æ­¤å¤–'
    ]
    
    text_lower = text.lower()
    count = sum(1 for p in patterns if p in text_lower)
    return count >= 2


def analyze_structure(text):
    """åˆ†æå¥å­çµæ§‹è¦å¾‹æ€§"""
    sentences = [s.strip() for s in text.split('ã€‚') if s.strip()]
    if len(sentences) < 2:
        return 0
    
    lengths = [len(s.split()) for s in sentences]
    variance = np.var(lengths) if len(lengths) > 1 else 0
    mean_len = np.mean(lengths) if lengths else 1
    
    cv = variance / (mean_len + 1)
    return 1 - min(1.0, cv / 3)


def count_contractions(text):
    """è¨ˆç®—ç¸®å¯«æ•¸é‡"""
    contractions = [
        "can't", "don't", "won't", "isn't", "hasn't",
        "haven't", "shouldn't", "couldn't", "wouldn't",
        "that's", "it's", "i'm", "you're", "i've"
    ]
    
    text_lower = text.lower()
    return sum(text_lower.count(c) for c in contractions)


def detect_natural_errors(text):
    """æª¢æ¸¬æ‰“å­—éŒ¯èª¤"""
    errors = 0
    
    double_words = ['the the', 'and and', 'a a', 'çš„çš„', 'å’Œå’Œ']
    for word in double_words:
        errors += text.lower().count(word)
    
    return errors / max(1, len(text.split()) / 10)


def detect_emotional_language(text):
    """æª¢æ¸¬æƒ…æ„Ÿè©å½™"""
    emotional = [
        'love', 'hate', 'beautiful', 'terrible', 'wonderful',
        'awful', 'amazing', 'fantastic', 'horrible', 'feel',
        'å–œæ­¡', 'è¨å­', 'ç¾', 'å¯æ€•', 'æ£’', 'ç³Ÿç³•', 'æ„Ÿå—'
    ]
    
    text_lower = text.lower()
    count = sum(1 for word in emotional if word in text_lower)
    return count / max(1, len(text.split()) / 5)


def detect_casual_language(text):
    """æª¢æ¸¬å£èªè¡¨é”"""
    casual = [
        'like', 'you know', 'basically', 'literally',
        'actually', 'honestly', 'pretty', 'kind of',
        'sort of', 'gonna', 'wanna', 'å°±åƒ', 'ä½ çŸ¥é“', 'åŸºæœ¬ä¸Š'
    ]
    
    text_lower = text.lower()
    count = sum(1 for word in casual if word in text_lower)
    return count / max(1, len(text.split()) / 5)


def detect_personal_opinions(text):
    """æª¢æ¸¬å€‹äººè§€é»"""
    opinions = [
        'i think', 'i believe', 'my opinion', 'i would say',
        'personally', 'to me', 'in my view',
        'æˆ‘èªç‚º', 'æˆ‘ç›¸ä¿¡', 'æˆ‘çš„çœ‹æ³•', 'å€‹äººä¾†èªª'
    ]
    
    text_lower = text.lower()
    count = sum(1 for op in opinions if op in text_lower)
    return count / max(1, len(text.split()) / 5)


def analyze_text(text, sensitivity):
    """åˆ†ææ–‡æœ¬ä¸¦è¿”å› AI/Human åˆ†æ•¸"""
    
    # === AI ç‰¹å¾µ ===
    ai_features = {}
    ai_scores = []
    
    # 1. é‡è¤‡çŸ­èª
    repeated = count_repeated_phrases(text)
    ai_features['é‡è¤‡çŸ­èªå¤š'] = repeated > 3
    if repeated > 3:
        ai_scores.append(0.15)
    
    # 2. æ­£å¼æªè¾­
    formal = detect_formal_language(text)
    ai_features['éåº¦æ­£å¼'] = formal > 0.6
    if formal > 0.6:
        ai_scores.append(0.12)
    
    # 3. å®Œç¾èªæ³•
    grammar = check_grammar_perfection(text)
    ai_features['èªæ³•å®Œç¾'] = grammar > 0.8
    if grammar > 0.8:
        ai_scores.append(0.12)
    
    # 4. æ¨¡å¼åŒ–è¡¨è¿°
    formulaic = check_formulaic_patterns(text)
    ai_features['æ¨¡å¼åŒ–çŸ­èª'] = formulaic
    if formulaic:
        ai_scores.append(0.10)
    
    # 5. çµæ§‹è¦å¾‹
    structure = analyze_structure(text)
    ai_features['çµæ§‹éè¦å¾‹'] = structure > 0.7
    if structure > 0.7:
        ai_scores.append(0.10)
    
    # === äººé¡ç‰¹å¾µ ===
    human_features = {}
    human_scores = []
    
    # 1. ç¸®å¯«ä½¿ç”¨
    contractions = count_contractions(text)
    human_features['ä½¿ç”¨ç¸®å¯«'] = contractions > 1
    if contractions > 1:
        human_scores.append(0.15)
    
    # 2. è‡ªç„¶éŒ¯èª¤
    errors = detect_natural_errors(text)
    human_features['è‡ªç„¶éŒ¯èª¤'] = errors > 0.01
    if errors > 0.01:
        human_scores.append(0.12)
    
    # 3. æƒ…æ„Ÿè©å½™
    emotion = detect_emotional_language(text)
    human_features['æƒ…æ„Ÿè¡¨ç¾'] = emotion > 0.05
    if emotion > 0.05:
        human_scores.append(0.15)
    
    # 4. å£èªè¡¨é”
    casual = detect_casual_language(text)
    human_features['å£èªç”¨è©'] = casual > 0.05
    if casual > 0.05:
        human_scores.append(0.12)
    
    # 5. å€‹äººè§€é»
    opinion = detect_personal_opinions(text)
    human_features['å€‹äººè§€é»'] = opinion > 0.05
    if opinion > 0.05:
        human_scores.append(0.10)
    
    # è¨ˆç®—åˆ†æ•¸
    ai_base = min(0.95, sum(ai_scores) + 0.15)
    human_base = min(0.95, sum(human_scores) + 0.1)
    
    total = ai_base + human_base
    ai_score = ai_base / total if total > 0 else 0.5
    human_score = 1 - ai_score
    
    # æ‡‰ç”¨éˆæ•åº¦
    if sensitivity < 0.75:
        ai_score = ai_score * 0.85
        human_score = 1 - ai_score
    elif sensitivity > 0.85:
        ai_score = min(0.99, ai_score * 1.15)
        human_score = 1 - ai_score
    
    details = {
        'ai_features': ai_features,
        'human_features': human_features
    }
    
    return ai_score, human_score, details


# ============================================================================
# Streamlit æ‡‰ç”¨é é¢
# ============================================================================

# è¨­å®šé é¢
st.set_page_config(
    page_title="AI vs Human æ–‡ç« åµæ¸¬å™¨",
    page_icon="ğŸ“",
    layout="wide"
)

# æ¨™é¡Œ
st.title("ğŸ¤– AI vs Human æ–‡ç« åµæ¸¬å™¨")
st.markdown("### ä½¿ç”¨æ–‡æœ¬ç‰¹å¾µåˆ†ææŠ€è¡“è¾¨åˆ¥æ–‡ç« ä¾†æº")
st.markdown("---")

# å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    sensitivity = st.slider("æª¢æ¸¬éˆæ•åº¦", 0.5, 1.0, 0.75, 0.05)
    st.info("éˆæ•åº¦è¶Šé«˜ï¼Œå° AI æ–‡æœ¬è¶Šæ•æ„Ÿ")

# ä¸»å®¹å™¨
col1, col2 = st.columns([3, 1])

with col1:
    st.subheader("ğŸ“„ è¼¸å…¥æ–‡æœ¬")
    user_text = st.text_area(
        "è²¼ä¸Šä½ è¦æª¢æ¸¬çš„æ–‡ç« ",
        height=300,
        placeholder="è‡³å°‘20å€‹å­—å…ƒ...",
        label_visibility="collapsed"
    )

with col2:
    st.subheader("ğŸ“Š çµ±è¨ˆ")
    if user_text:
        words = user_text.split()
        st.metric("å­—å…ƒ", len(user_text))
        st.metric("è©æ•¸", len(words))
    else:
        st.info("è¼¸å…¥æ–‡æœ¬å¾Œé¡¯ç¤ºçµ±è¨ˆ")

st.markdown("---")

# åˆ†ææŒ‰éˆ•
if st.button("ğŸ” é–‹å§‹åˆ†æ", use_container_width=True):
    if not user_text or len(user_text.strip()) < 20:
        st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ 20 å€‹å­—å…ƒ")
    else:
        with st.spinner("åˆ†æä¸­..."):
            time.sleep(0.5)
            
            # åŸ·è¡Œåˆ†æ
            ai_score, human_score, details = analyze_text(user_text, sensitivity)
            
            st.markdown("---")
            st.subheader("ğŸ¯ æª¢æ¸¬çµæœ")
            
            col_ai, col_human = st.columns(2)
            with col_ai:
                st.metric("ğŸ¤– AI ç”Ÿæˆ", f"{ai_score*100:.1f}%")
            with col_human:
                st.metric("ğŸ‘¤ äººé¡æ’°å¯«", f"{human_score*100:.1f}%")
            
            # é€²åº¦æ¢
            st.progress(ai_score, text="AI å¯èƒ½æ€§")
            
            st.markdown("---")
            st.subheader("ğŸ“‹ è©³ç´°ç‰¹å¾µåˆ†æ")
            
            col_ai_feat, col_human_feat = st.columns(2)
            with col_ai_feat:
                st.write("**AI ç‰¹å¾µ**")
                for feat, score in details['ai_features'].items():
                    st.write(f"{'âœ…' if score else 'âŒ'} {feat}")
            
            with col_human_feat:
                st.write("**äººé¡ç‰¹å¾µ**")
                for feat, score in details['human_features'].items():
                    st.write(f"{'âœ…' if score else 'âŒ'} {feat}")
            
            st.markdown("---")
            st.subheader("ğŸ’¡ çµè«–")
            
            if ai_score > 0.75:
                st.error("âš ï¸ **é«˜åº¦å¯èƒ½æ˜¯ AI ç”Ÿæˆ**")
                st.write("ç‰¹å¾µ: é«˜åº¦çµæ§‹åŒ–ã€èªæ³•å®Œç¾ã€ç¼ºä¹å€‹äººé¢¨æ ¼")
            elif ai_score > 0.55:
                st.warning("ğŸ¤” **å¯èƒ½åŒ…å« AI æˆåˆ†**")
                st.write("é€™ç¯‡æ–‡ç« å¯èƒ½ç”± AI éƒ¨åˆ†æ’°å¯«æˆ–å¤§é‡ç·¨è¼¯")
            else:
                st.success("âœ… **å¾ˆå¯èƒ½æ˜¯äººé¡æ’°å¯«**")
                st.write("ç‰¹å¾µ: è‡ªç„¶è¡¨é”ã€å€‹äººé¢¨æ ¼ã€æƒ…æ„Ÿè¡¨ç¾")

st.markdown("---")
st.markdown("<div style='text-align: center; color: #888; font-size: 11px;'>AI vs Human æ–‡ç« åµæ¸¬å™¨ | HW5 Q1</div>", unsafe_allow_html=True)

